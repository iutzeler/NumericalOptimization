{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"Fig/UGA.png\" width=\"30%\" height=\"30%\"></center>\n",
    "<center><h3>Master of Science in Industrial and Applied Mathematics (MSIAM)  - 1st year</h3></center>\n",
    "<hr>\n",
    "<center><h1>Numerical Optimization</h1></center>\n",
    "<center><h2>Lab 9: Min-Max problem and Zero-sum games</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider a game with 2 players, both having $n$ possible actions.\n",
    "\n",
    "\n",
    "They play against each other and whenever Player 1 plays action \\#i and Player 2 plays action \\#j, P1 gets a reward of $g_{ij}\\in\\mathbb{R}$ while P2 gets $-g_{ij}\\in\\mathbb{R}$ (hence the name zero sum).\n",
    "\n",
    "\n",
    "The goal for both players is to find a Nash Equilibrium, that is a probability distribution over the actions for each player such that neither player has an individual interest to deviate from this strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulation of the Nash Equilibrium as the solution of a Min-Max problem\n",
    "\n",
    "Let us denote by $x$ the probability distribution of the actions of P1 (its \"strategy\"), and $y$ the one of P2. \n",
    "\n",
    "Both $x$ and $y$ are probability distributions over $n$ possible actions, thus they both belong to the simplex of size n:\n",
    "$$ \\Delta_n = \\left\\{ p \\in \\mathbb{R}^n : p\\geq 0 , \\sum_{i=1}^n  p_i = 1 \\right\\} . $$\n",
    "\n",
    "\n",
    "Then, it can be shown that the NE is achieved by $(x^\\star,y^\\star)$ solution of the problems\n",
    "\\begin{align}\n",
    "\\tag{P1}\n",
    " x^\\star = \\arg\\max_{x\\in\\Delta_n} \\min_{y\\in\\Delta_n} x^\\top A y\n",
    "\\end{align}\n",
    "where $A$ is the $n\\times n$ matrix such that $A_{ij} = g_{ij}$, the reward of P1 for actions $i$ and $j$.\n",
    "\n",
    "Similarly, we have\n",
    "\\begin{align}\n",
    "\\tag{P2}\n",
    " y^\\star = \\arg\\min_{y\\in\\Delta_n} \\max_{x\\in\\Delta_n} x^\\top A y\n",
    "\\end{align}\n",
    "with the same matrix $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical computation of constrained Min-Max problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will first consider a zero-sum game characterized by matrix $A=\\left[\\begin{array}{cc} -6 & 9 \\\\  4 & -6 \\end{array}\\right]$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as scopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2; m =2 # Dimension\n",
    "A = np.array([[-6,9],[4,-6]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: Linear Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal strategy for x\n",
    "\n",
    "We begin by finding the optimal $x^\\star$.\n",
    "\n",
    "> **1.** Reformulate the problem (P1) into a linear program and solve it using a LP solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal strategy for y\n",
    "\n",
    "> **2.** Do the same thing with (P2) to find $y^\\star$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value of the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.** Compare the values of problems (P1) and (P2). What is remarkable about $A y^\\star$? About $A^\\top x^\\star$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: Optimization \n",
    "\n",
    "Finding the solution of a min-max optimization problem is harder in general than for a simple minimization problem. Nevertheless, it can still be achieved by first-order ``gradient-like'' methods. This kind of setup has attracted a lot of interest in the 2020's for the training of Generative Adversarial Networks (GANs). \n",
    "\n",
    "To do so, we can define $X=(x,y)\\in \\Delta_n\\times\\Delta_n$ and $v(X) = (-A y, A^\\top x)$. To solve the problem\n",
    "\\begin{align}\n",
    "\\tag{P}\n",
    "\\max_{x\\in\\Delta_n} \\min_{y\\in\\Delta_n}  x^\\top A y ,\n",
    "\\end{align}\n",
    "we can try to move oppositely to its direction (ie. do a gradient ascent on $ x\\mapsto x^\\top A y $ and a gradient descent on  $ y\\mapsto x^\\top A y $:\n",
    "\\begin{align}\n",
    "    \\tag{Gradient Descent Ascent}\n",
    "    X_{k+1} = \\mathrm{proj}_{\\Delta_n\\times\\Delta_n} (X_k-\\gamma_k v(X_k)).\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "We first define the vector field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v(X):\n",
    "    x = X[0:n]\n",
    "    y = X[n:]\n",
    "    return np.concatenate((-A.dot(y),A.T.dot(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the dimension of the variables space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2*n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the projection to the contraints: $\\Delta_n\\times\\Delta_n$\n",
    "\n",
    "> **4.** Implement a function that projects a vector onto $\\Delta_n\\times\\Delta_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_simplex(v):\n",
    "    ## TODO\n",
    "    return v\n",
    "\n",
    "def proj_2simplex(X):\n",
    "    x = X[0:n]\n",
    "    y = X[n:]\n",
    "    return np.concatenate((proj_simplex(x),proj_simplex(y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent-Ascent\n",
    "\n",
    "> **5.** Run Gradient Descent Ascent by completing the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = proj_2simplex(np.ones(N))\n",
    "K = 1000\n",
    "step = 0.01\n",
    "\n",
    "X_tab_GDA = np.copy(X)\n",
    "\n",
    "for k in range(1,K):\n",
    "    X = X ## Step to fill\n",
    "    if k%5==0:\n",
    "        if k%25==0: print(\"ite. {:3d} : x= [{:.3f},{:.3f}] | y= [{:.3f},{:.3f}]\".format(k,X[0],X[1],X[2],X[3]))\n",
    "        X_tab_GDA = np.vstack((X_tab_GDA,X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **6.** What do you observe in terms of convergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extragradient\n",
    "\n",
    "To overcome the issues with gradient descent-ascent, the ExtraGradient method was proposed:\n",
    "\\begin{align}\n",
    "    \\tag{ExtraGradient}\n",
    "    \\left\\{ \n",
    "        \\begin{array}{l}\n",
    "            X_{k+1/2} = \\mathrm{proj}_{\\Delta_n\\times\\Delta_n} (X_k-\\gamma_k v(X_k) ) \\\\\n",
    "        X_{k+1} =  \\mathrm{proj}_{\\Delta_n\\times\\Delta_n} (X_k-\\gamma_k v(X_{k+1/2})))\n",
    "        \\end{array}\n",
    "    \\right. \n",
    "\\end{align}\n",
    "which intuitively consists in generating a leading point that will look forward the value of the field and apply it to the base point. This way, circular effects can be managed and convergence can be restored.\n",
    "\n",
    "\n",
    "> **7.** Run ExtraGradient by completing the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = proj_2simplex(np.ones(N))\n",
    "K = 1000\n",
    "step = 0.01\n",
    "\n",
    "X_tab_EG = np.copy(X)\n",
    "\n",
    "for k in range(1,K):\n",
    "    X_lead = X ## Step to fill\n",
    "    X      = X ## Step to fill\n",
    "    if k%5==0:\n",
    "        if k%25==0: print(\"ite. {:3d} : x= [{:.3f},{:.3f}] | y= [{:.3f},{:.3f}]\".format(k,X_lead[0],X_lead[1],X_lead[2],X_lead[3]))\n",
    "        X_tab_EG = np.vstack((X_tab_EG,X_lead))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison\n",
    "\n",
    "> **8.** Compare Gradient and ExtraGradient on the plot below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X_tab_GDA[:,0],X_tab_GDA[:,2],color=\"red\",label=\"GDA\")\n",
    "plt.plot(X_tab_EG[:,0],X_tab_EG[:,2],color=\"blue\",label=\"EG\")\n",
    "plt.title(\"Behavior of x[1] and y[1]\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mirror Prox\n",
    "\n",
    "A possibility to make the projections above easier to compute is to change the (implicit) Euclidean metric.\n",
    "    For the simplex, an efficient example is the \\emph{Kullback-Liebler} divergence $D(x,y) = \\sum_{i=1}^n x_i\\log(x_i/y_i) - \\sum_{i=1}^n (x_i-y_i)$, which serve as a metric on strictly positive vectors.\n",
    "    \n",
    "With this metric, for any positive vector $y$,\n",
    "    \\begin{align}\n",
    "        \\mathrm{proj}^{KL}_{\\Delta_n} (y) = \\arg\\min_{u\\in\\Delta_n} D(u,y)  = \\frac{y}{ \\sum_{i=1}^n y_i} = \\frac{y}{ \\|y\\|_1}\n",
    "    \\end{align}\n",
    "    which is much easier to compute.\n",
    "    \n",
    "By changing the metric of the Extragradient algorithm, by going from $X_{k+1}=\\arg\\min_X\\{ -\\gamma\\langle v(X_k),X\\rangle + \\frac{1}{2} \\|X-X_k\\|^2 \\}$ to $X_{k+1}=\\arg\\min_X\\{ -\\gamma\\langle v(X_k),X\\rangle + D(X,X_k) \\}$} we obtain the Mirror-Prox method.\n",
    "\n",
    "\n",
    "> **9.** Show that \n",
    "> $$ \\arg\\min_X\\{ -\\gamma\\langle v(X_k),X\\rangle + D(X,X_k) \\} = X_k \\exp(-\\gamma v(X_{k} )) $$\n",
    "\n",
    "\n",
    "The Mirror Prox algorithm then writes:\n",
    "    \\begin{align}\n",
    "        \\tag{Mirror Prox}\n",
    "        \\left\\{ \n",
    "            \\begin{array}{l}\n",
    "            (a_{k+1/2},b_{k+1/2}) = X_k \\exp(-\\gamma v(X_k)) \\\\\n",
    "            X_{k+1/2} = (\\frac{a_{k+1/2}}{\\|a_{k+1/2}\\|_1},\\frac{b_{k+1/2}}{\\|,b_{k+1/2}\\|_1}) \\\\\n",
    "            (a_{k+1},b_{k+1}) = X_k \\exp(-\\gamma v(X_{k+1/2})) \\\\\n",
    "            X_{k+1} = (\\frac{a_{k+1}}{\\|a_{k+1}\\|_1},\\frac{b_{k+1}}{\\|,b_{k+1}\\|_1}) \\\\\n",
    "            \\end{array}\n",
    "        \\right. .\n",
    "    \\end{align}\n",
    "\n",
    "\n",
    "This is ExtraGradient but with this adapted geometry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **10.** Run Mirror Prox by completing the code below and compare its behavior with the previous methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = proj_2simplex(np.ones(N))\n",
    "K = 1000\n",
    "step = 0.05\n",
    "\n",
    "X_tab_MP = np.copy(X)\n",
    "\n",
    "for k in range(1,K):\n",
    "    X_lead = X_lead ## Step to fill\n",
    "    if k%1==0:\n",
    "        if k%25==0: print(\"ite. {:3d} : x= [{:.3f},{:.3f}] | y= [{:.3f},{:.3f}]\".format(k,X_lead[0],X_lead[1],X_lead[2],X_lead[3]))\n",
    "        X_tab_MP = np.vstack((X_tab_MP,X_lead))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X_tab_GDA[:,0],X_tab_GDA[:,2],color=\"red\",label=\"GDA\")\n",
    "plt.plot(X_tab_EG[:,0],X_tab_EG[:,2],color=\"blue\",label=\"EG\")\n",
    "plt.plot(X_tab_MP[:,0],X_tab_MP[:,2],color=\"green\",label=\"MP\")\n",
    "plt.title(\"Behavior of x[1] and y[1]\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
