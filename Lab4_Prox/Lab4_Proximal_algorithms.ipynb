{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"Fig/UGA.png\" width=\"30%\" height=\"30%\"></center>\n",
    "<center><h3>Master of Science in Industrial and Applied Mathematics (MSIAM)  - 1st year</h3></center>\n",
    "<hr>\n",
    "<center><h1>Numerical Optimization</h1></center>\n",
    "<center><h2>Lab 4: Proximal Algorithms</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Composite minimization.\n",
    "\n",
    "In this lab, we will investigate optimization algorithms over composite functions composed of a smooth and a non-smooth part using the proximal gradient algorithm over a practical problem of machine learning: binary classification using logistic regression.</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider the following function\n",
    " \n",
    "\\begin{align*}\n",
    "\\min_{x\\in\\mathbb{R}^d } F(x) := \\underbrace{ \\frac{1}{m}  \\sum_{i=1}^m  \\log( 1+\\exp(-b_i \\langle a_i,x \\rangle) ) + \\frac{\\lambda_2}{2} \\|x\\|_2^2}_{f(x)} + \\underbrace{\\lambda_1 \\|x\\|_1 }_{g(x)}.\n",
    "\\end{align*}\n",
    "\n",
    "for which we give:\n",
    "* the oracles for functions $f, g, F$;\n",
    "* the gradient oracle for $f$ and the Lipchitz constant of the gradient;\n",
    "* the size of the problem $n$;\n",
    "\n",
    "in `logistic_regression_student.py`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Implement the proximal operation linked to $g(x) = \\lambda_1 \\|x\\|_1$ in `logistic_regression_student.py`. \n",
    "\n",
    "> Create a function coding the proximal gradient algorithm and test your algorithm below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logistic_regression_student as pb\n",
    "\n",
    "\n",
    "##### proximal gradient algorithm\n",
    "#x,x_tab = proximal_gradient_algorithm(pb.F , pb.f_grad , pb.g_prox , x0 , step , PREC, ITE_MAX , True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Investigate the decrease of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot the support of the vector $x_k$ (i.e. one point for every non-null coordinate of $x_k$) versus the iterations. \n",
    "\n",
    "> What do you notice? Was it expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Regularization path.\n",
    "\n",
    "\n",
    "We saw above that the algorithm *selected* some coordinates as the other get to zero. Considering our machine learning task, this translates into the algorithm selecting a subset of the features that will be used for the prediction step (see also the features signification at the end of the notebook).  \n",
    "\n",
    "> Change the parameter $\\lambda_1$ of the problem (`pb.lam1`) in the code above and investigate how it influences the number of selected features.\n",
    "\n",
    "In order to quantify the influence of this feature selection, let us consider the *regularization path* that is the support of the final points obtained by our minimization method versus the value of $\\lambda_1$.\n",
    "\n",
    "> For $\\lambda_1 = 2^{-12},2^{-11}, .. , 2^{1}$, run the proximal gradient algorithm on the obtained problem and store the support of the final point, the prediction performance on the *training set* (`pb.prediction_train`) and on the *testing set* (`pb.prediction_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import logistic_regression_student as pb\n",
    "\n",
    "\n",
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot the *regularization path* and look at the feature signification (at the end of the notebook) to see which are the most important features of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot the *training* and *testing* accuracies versus the value of $\\lambda_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features signification\n",
    "\n",
    "The dataset is comprised of $27$ features described below and the goal is to predict if the student may pass its year or not. It is thus of importance to investigate which features are the most significant for the student success. We will see how the $\\ell_1$ regularization can help to this goal."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1 sex - student's sex (binary: \"F\" - female or \"M\" - male)\n",
    "2 age - student's age (numeric: from 15 to 22)\n",
    "3 address - student's home address type (binary: \"U\" - urban or \"R\" - rural)\n",
    "4 famsize - family size (binary: \"LE3\" - less or equal to 3 or \"GT3\" - greater than 3)\n",
    "5 Pstatus - parent's cohabitation status (binary: \"T\" - living together or \"A\" - apart)\n",
    "6 Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    "7 Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n",
    "8 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    "9 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "10 failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n",
    "11 schoolsup - extra educational support (binary: yes or no)\n",
    "12 famsup - family educational support (binary: yes or no)\n",
    "13 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    "14 activities - extra-curricular activities (binary: yes or no)\n",
    "15 nursery - attended nursery school (binary: yes or no)\n",
    "16 higher - wants to take higher education (binary: yes or no)\n",
    "17 internet - Internet access at home (binary: yes or no)\n",
    "18 romantic - with a romantic relationship (binary: yes or no)\n",
    "19 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "20 freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "21 goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "22 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "23 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "24 health - current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "25 absences - number of school absences (numeric: from 0 to 93)\n",
    "26 G1 - first period grade (numeric: from 0 to 20)\n",
    "27 G2 - second period grade (numeric: from 0 to 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
